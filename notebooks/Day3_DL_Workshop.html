
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>CNN &#8212; Deep Learning Using PyTorch</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/Day3_DL_Workshop';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="RNN" href="Day4_DL_Workshop.html" />
    <link rel="prev" title="Artificial Neural Networks" href="Day2_DL_Workshop.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning Using PyTorch</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../README.html">
                    Deep-Learning-using-PyTorch Notes
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Day1_DL_pytorch.html">Tensor attributes</a></li>







<li class="toctree-l1"><a class="reference internal" href="Day2_DL_Workshop.html">Artificial Neural Networks</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">CNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="Day4_DL_Workshop.html">RNN</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/Day3_DL_Workshop.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>CNN</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a href="https://colab.research.google.com/github/the-y9/Deep-Learning-using-PyTorch/blob/main/Day3_DL_Workshop.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="cnn">
<h1>CNN<a class="headerlink" href="#cnn" title="Link to this heading">#</a></h1>
<p>The movie was fantastic</p>
<ul class="simple">
<li><p><strong>seq lenghth</strong> = 4</p></li>
<li><p><strong>input/embedded dimension</strong> = 5(state vector dimensions)</p></li>
<li><p><strong>hidden dimension</strong></p></li>
<li><p><strong>Linear layer</strong> for final output
<span class="math notranslate nohighlight">\( h_0 -&gt;h_1-&gt;h_2-&gt;h_3-&gt;h_4 \)</span>
<span class="math notranslate nohighlight">\(  \)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;torch&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="c1"># efficient in creating batches and in the process of itrating tohrough batches during</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
<span class="n">help</span><span class="p">(</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on class FashionMNIST in module torchvision.datasets.mnist:

class FashionMNIST(MNIST)
 |  FashionMNIST(root: Union[str, pathlib.Path], train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -&gt; None
 |  
 |  `Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.
 |  
 |  Args:
 |      root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``
 |          and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.
 |      train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,
 |          otherwise from ``t10k-images-idx3-ubyte``.
 |      download (bool, optional): If True, downloads the dataset from the internet and
 |          puts it in root directory. If dataset is already downloaded, it is not
 |          downloaded again.
 |      transform (callable, optional): A function/transform that  takes in a PIL image
 |          and returns a transformed version. E.g, ``transforms.RandomCrop``
 |      target_transform (callable, optional): A function/transform that takes in the
 |          target and transforms it.
 |  
 |  Method resolution order:
 |      FashionMNIST
 |      MNIST
 |      torchvision.datasets.vision.VisionDataset
 |      torch.utils.data.dataset.Dataset
 |      typing.Generic
 |      builtins.object
 |  
 |  Data and other attributes defined here:
 |  
 |  __annotations__ = {}
 |  
 |  __parameters__ = ()
 |  
 |  classes = [&#39;T-shirt/top&#39;, &#39;Trouser&#39;, &#39;Pullover&#39;, &#39;Dress&#39;, &#39;Coat&#39;, &#39;San...
 |  
 |  mirrors = [&#39;http://fashion-mnist.s3-website.eu-central-1.amazonaws.com...
 |  
 |  resources = [(&#39;train-images-idx3-ubyte.gz&#39;, &#39;8d4fb7e6c68d591d4c3dfef9e...
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from MNIST:
 |  
 |  __getitem__(self, index: int) -&gt; Tuple[Any, Any]
 |      Args:
 |          index (int): Index
 |      
 |      Returns:
 |          tuple: (image, target) where target is index of the target class.
 |  
 |  __init__(self, root: Union[str, pathlib.Path], train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -&gt; None
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  __len__(self) -&gt; int
 |  
 |  download(self) -&gt; None
 |      Download the MNIST data if it doesn&#39;t exist already.
 |  
 |  extra_repr(self) -&gt; str
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from MNIST:
 |  
 |  class_to_idx
 |  
 |  processed_folder
 |  
 |  raw_folder
 |  
 |  test_data
 |  
 |  test_labels
 |  
 |  train_data
 |  
 |  train_labels
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from MNIST:
 |  
 |  test_file = &#39;test.pt&#39;
 |  
 |  training_file = &#39;training.pt&#39;
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from torchvision.datasets.vision.VisionDataset:
 |  
 |  __repr__(self) -&gt; str
 |      Return repr(self).
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from torch.utils.data.dataset.Dataset:
 |  
 |  __add__(self, other: &#39;Dataset[T_co]&#39;) -&gt; &#39;ConcatDataset[T_co]&#39;
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from torch.utils.data.dataset.Dataset:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:
 |  
 |  __orig_bases__ = (typing.Generic[+T_co],)
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from typing.Generic:
 |  
 |  __class_getitem__(params) from builtins.type
 |  
 |  __init_subclass__(*args, **kwargs) from builtins.type
 |      This method is called when a class is subclassed.
 |      
 |      The default implementation does nothing. It may be
 |      overridden to extend subclasses.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="s1">&#39;.data&#39;</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">download</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to .data/FashionMNIST/raw/train-images-idx3-ubyte.gz
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 26421880/26421880 [00:01&lt;00:00, 17215704.37it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting .data/FashionMNIST/raw/train-images-idx3-ubyte.gz to .data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to .data/FashionMNIST/raw/train-labels-idx1-ubyte.gz
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 29515/29515 [00:00&lt;00:00, 274193.07it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting .data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to .data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to .data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 4422102/4422102 [00:00&lt;00:00, 4937716.98it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting .data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to .data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to .data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 5148/5148 [00:00&lt;00:00, 3161850.49it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting .data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to .data/FashionMNIST/raw
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>60000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_data</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(torch.Size([60000, 28, 28]), torch.Size([60000]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">train_data</span><span class="o">.</span><span class="n">classes</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">train_data</span><span class="o">.</span><span class="n">class_to_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;T-shirt/top&#39;, &#39;Trouser&#39;, &#39;Pullover&#39;, &#39;Dress&#39;, &#39;Coat&#39;, &#39;Sandal&#39;, &#39;Shirt&#39;, &#39;Sneaker&#39;, &#39;Bag&#39;, &#39;Ankle boot&#39;],
 {&#39;T-shirt/top&#39;: 0, &#39;Trouser&#39;: 1, &#39;Pullover&#39;: 2, &#39;Dress&#39;: 3, &#39;Coat&#39;: 4, &#39;Sandal&#39;: 5, &#39;Shirt&#39;: 6, &#39;Sneaker&#39;: 7, &#39;Bag&#39;: 8, &#39;Ankle boot&#39;: 9}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;PIL.Image.Image image mode=L size=28x28&gt;, 9)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/adf48a208b1e9f1a3b4756de5ea2d382077db8d5c9393bb6f782fc97580efbc4.png" src="../_images/adf48a208b1e9f1a3b4756de5ea2d382077db8d5c9393bb6f782fc97580efbc4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.image.AxesImage at 0x7b901ad7cf70&gt;
</pre></div>
</div>
<img alt="../_images/3f6bbe7406c36ad98fcd3671bf0397bdcebdad4380d2474932dd0f89fc74d85a.png" src="../_images/3f6bbe7406c36ad98fcd3671bf0397bdcebdad4380d2474932dd0f89fc74d85a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;AugMix&#39;,
 &#39;AutoAugment&#39;,
 &#39;AutoAugmentPolicy&#39;,
 &#39;CenterCrop&#39;,
 &#39;ColorJitter&#39;,
 &#39;Compose&#39;,
 &#39;ConvertImageDtype&#39;,
 &#39;ElasticTransform&#39;,
 &#39;FiveCrop&#39;,
 &#39;GaussianBlur&#39;,
 &#39;Grayscale&#39;,
 &#39;InterpolationMode&#39;,
 &#39;Lambda&#39;,
 &#39;LinearTransformation&#39;,
 &#39;Normalize&#39;,
 &#39;PILToTensor&#39;,
 &#39;Pad&#39;,
 &#39;RandAugment&#39;,
 &#39;RandomAdjustSharpness&#39;,
 &#39;RandomAffine&#39;,
 &#39;RandomApply&#39;,
 &#39;RandomAutocontrast&#39;,
 &#39;RandomChoice&#39;,
 &#39;RandomCrop&#39;,
 &#39;RandomEqualize&#39;,
 &#39;RandomErasing&#39;,
 &#39;RandomGrayscale&#39;,
 &#39;RandomHorizontalFlip&#39;,
 &#39;RandomInvert&#39;,
 &#39;RandomOrder&#39;,
 &#39;RandomPerspective&#39;,
 &#39;RandomPosterize&#39;,
 &#39;RandomResizedCrop&#39;,
 &#39;RandomRotation&#39;,
 &#39;RandomSolarize&#39;,
 &#39;RandomVerticalFlip&#39;,
 &#39;Resize&#39;,
 &#39;TenCrop&#39;,
 &#39;ToPILImage&#39;,
 &#39;ToTensor&#39;,
 &#39;TrivialAugmentWide&#39;,
 &#39;__builtins__&#39;,
 &#39;__cached__&#39;,
 &#39;__doc__&#39;,
 &#39;__file__&#39;,
 &#39;__loader__&#39;,
 &#39;__name__&#39;,
 &#39;__package__&#39;,
 &#39;__path__&#39;,
 &#39;__spec__&#39;,
 &#39;_functional_pil&#39;,
 &#39;_functional_tensor&#39;,
 &#39;_presets&#39;,
 &#39;autoaugment&#39;,
 &#39;functional&#39;,
 &#39;transforms&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="c1">#shows channel = 1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([60000, 28, 28])
</pre></div>
</div>
</div>
</div>
<p><strong>ToTensor()</strong></p>
<p>Converts images into tensor and then standardise dataset (PIL)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="n">transform1</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">((</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">))))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="s1">&#39;.data&#39;</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">transform</span> <span class="o">=</span> <span class="n">transform1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># but.dat[0][0] does not change</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000,
           -1.0000, -0.8980, -0.4275, -1.0000, -1.0000, -0.9922, -0.9686,
           -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -0.9922, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -1.0000,
           -0.7176,  0.0667, -0.0039, -0.5137, -0.5765, -1.0000, -1.0000,
           -1.0000, -0.9922, -0.9765, -0.9686, -1.0000, -1.0000, -0.9765],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529, -1.0000,
           -0.2000,  0.6000,  0.3804,  0.0510,  0.1294, -0.0353, -0.8196,
           -1.0000, -1.0000, -1.0000, -1.0000, -0.9059, -0.9216, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
            0.2157,  0.8510,  0.6235,  0.3961, -0.1608,  0.2235,  0.2627,
           -0.1451, -0.4980, -0.8196, -0.3961,  0.0196, -0.4353, -0.8824],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000, -0.4588,
            0.6235,  0.7490,  0.7098,  0.6941,  0.6941,  0.2784, -0.0039,
           -0.0510, -0.0431,  0.1451,  0.1059, -0.3098,  0.3490, -0.4824],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -0.9922, -0.9922, -0.9922, -1.0000,  0.5686,
            0.8196,  0.8196,  0.8275,  0.7961,  0.7490,  0.7490,  0.6863,
            0.6706,  0.2863, -0.0039, -0.0353,  0.5373,  0.7961, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.4353,
            0.7647,  0.6941,  0.7490,  0.7882,  0.8431,  0.7804,  0.7569,
            0.7412,  0.7569,  0.7333,  0.7490,  0.9216,  0.3569, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5137,
            0.7882,  0.7098,  0.6706,  0.5529,  0.4118,  0.6627,  0.6471,
            0.6549,  0.6706,  0.7490,  0.7255,  0.9059,  0.5843, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -0.9922, -0.9765, -1.0000, -0.9059,  0.7176,
            0.7255,  0.6627,  0.7098,  0.5059,  0.3255,  0.7804,  0.6314,
            0.7098,  0.7569,  0.6627,  0.7725,  0.5451,  0.6392, -0.5922],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -0.9529, -1.0000, -0.2235,  0.9137,
            0.7412,  0.7255,  0.7098,  0.5922,  0.5529,  0.7333,  0.6863,
            0.6706,  0.7412,  0.7255,  0.9216, -0.0667,  0.3098, -0.5608],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -0.9686, -1.0000, -1.0000, -0.5686,  0.8510,
            0.7882,  0.8039,  0.7882,  0.8824,  0.8196,  0.6706,  0.7098,
            0.7490,  0.8353,  0.7020,  0.7020,  0.6392, -0.2784, -1.0000],
          [-1.0000, -1.0000, -0.9922, -0.9686, -0.9529, -0.9451, -0.9843,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8588,  0.7725,
            0.7020,  0.7490,  0.7412,  0.7176,  0.7412,  0.7333,  0.6941,
            0.7490,  0.7961,  0.6863,  0.7098,  1.0000, -0.3961, -1.0000],
          [-1.0000, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -0.5137,  0.1373,  0.6000,  0.7882,  0.6235,
            0.6706,  0.7333,  0.7098,  0.6314,  0.6549,  0.7098,  0.7569,
            0.7490,  0.7176,  0.6863,  0.7569,  0.9137,  0.2471, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -0.8588, -0.6549, -0.3569,
           -0.1608,  0.4824,  0.7882,  0.7255,  0.7412,  0.7020,  0.7725,
            0.5686,  0.6078,  0.6549,  0.8039,  0.7569,  0.8353,  0.3804,
            0.4745,  0.9608,  0.9451,  0.8275,  0.8667,  0.6863, -1.0000],
          [-1.0000, -0.5529,  0.4667,  0.6314,  0.7569,  0.7333,  0.7569,
            0.6314,  0.6000,  0.6784,  0.6314,  0.6392,  0.5686,  0.2471,
            0.9216,  0.5137,  0.6157,  0.7490,  1.0000,  1.0000,  0.7333,
            0.8353,  0.7333,  0.6549,  0.7255,  0.8196,  0.9294, -1.0000],
          [-0.9765,  0.5843,  0.7882,  0.7569,  0.7333,  0.6549,  0.6549,
            0.6784,  0.6078,  0.6078,  0.6078,  0.7255,  0.8824, -0.3725,
            0.1765,  1.0000,  0.7961,  0.7333,  0.4745,  0.2078,  0.4980,
            0.6471,  0.6000,  0.6392,  0.7412,  0.7882,  0.7647, -1.0000],
          [-0.2314,  0.8275,  0.5529,  0.6471,  0.7412,  0.7961,  0.7961,
            0.8353,  0.9529,  0.7255,  0.5216,  0.6863,  0.7020,  0.8902,
           -0.4902, -0.4275, -0.1686, -0.0824,  0.3176,  0.7176,  0.7333,
            0.6863,  0.7020,  0.7490,  0.7490,  0.7569,  0.7961, -0.7725],
          [-0.4118,  0.6000,  0.6627,  0.6000,  0.5137,  0.6078,  0.6549,
            0.7647,  0.6941,  0.4510,  0.5451,  0.6157,  0.5529,  0.6706,
            0.8824,  0.5294,  0.7804,  0.9216,  0.8745,  0.7490,  0.7098,
            0.6627,  0.6392,  0.7412,  0.7255,  0.7333,  0.8039, -0.4745],
          [-0.6235,  0.5922,  0.4353,  0.5216,  0.6706,  0.5451,  0.4510,
            0.4902,  0.5216,  0.5059,  0.5843,  0.6784,  0.7176,  0.7333,
            0.7255,  0.8510,  0.7647,  0.6941,  0.5608,  0.6157,  0.4588,
            0.4196,  0.3882,  0.3490,  0.4196,  0.6078,  0.6157, -0.0980],
          [-1.0000, -0.0431,  0.7176,  0.5137,  0.4039,  0.3412,  0.4353,
            0.5373,  0.6000,  0.6471,  0.6706,  0.6235,  0.6549,  0.6471,
            0.5686,  0.5373,  0.5216,  0.4980,  0.5294,  0.4980,  0.5529,
            0.5059,  0.3804,  0.2235,  0.3098,  0.3882,  0.6471, -0.2784],
          [-1.0000, -1.0000, -0.4196,  0.4824,  0.6627,  0.4980,  0.3725,
            0.3490,  0.3725,  0.4196,  0.4510,  0.4745,  0.4824,  0.4745,
            0.5137,  0.5529,  0.6000,  0.6392,  0.6471,  0.6471,  0.6549,
            0.4745,  0.4745,  0.5216,  0.5059,  0.6941,  0.3333, -1.0000],
          [-0.9843, -1.0000, -1.0000, -1.0000, -0.4824,  0.5686,  0.7412,
            0.8588,  0.8745,  0.8980,  0.9294,  0.9059,  0.9137,  0.7333,
            0.7255,  0.5137,  0.4980,  0.4039,  0.4275,  0.4275,  0.4196,
            0.3804,  0.3020,  0.3176, -0.2235, -0.5451, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -0.6863, -0.5216, -0.6549, -0.4353, -0.6784, -0.7255, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,
           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]),
 9)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transform2</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">((</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">,</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">))))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s1">&#39;.data&#39;</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">transform</span> <span class="o">=</span> <span class="n">transform2</span> <span class="p">)</span><span class="c1"># download = True)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="c1">#3 channels</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(50000, 32, 32, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
      .ndarray_repr .ndarray_raw_data {
        display: none;
      }
      .ndarray_repr.show_array .ndarray_raw_data {
        display: block;
      }
      .ndarray_repr.show_array .ndarray_image_preview {
        display: none;
      }
      </style>
      <div id="id-55111274-862b-469d-9dd8-15b48d3d6fcd" class="ndarray_repr"><pre>ndarray (32, 32, 3) <button style="padding: 0 2px;">show data</button></pre><img src="data:image/png;base64,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" class="ndarray_image_preview" /><pre class="ndarray_raw_data">array([[[ 59,  62,  63],
        [ 43,  46,  45],
        [ 50,  48,  43],
        ...,
        [158, 132, 108],
        [152, 125, 102],
        [148, 124, 103]],

       [[ 16,  20,  20],
        [  0,   0,   0],
        [ 18,   8,   0],
        ...,
        [123,  88,  55],
        [119,  83,  50],
        [122,  87,  57]],

       [[ 25,  24,  21],
        [ 16,   7,   0],
        [ 49,  27,   8],
        ...,
        [118,  84,  50],
        [120,  84,  50],
        [109,  73,  42]],

       ...,

       [[208, 170,  96],
        [201, 153,  34],
        [198, 161,  26],
        ...,
        [160, 133,  70],
        [ 56,  31,   7],
        [ 53,  34,  20]],

       [[180, 139,  96],
        [173, 123,  42],
        [186, 144,  30],
        ...,
        [184, 148,  94],
        [ 97,  62,  34],
        [ 83,  53,  34]],

       [[177, 144, 116],
        [168, 129,  94],
        [179, 142,  87],
        ...,
        [216, 184, 140],
        [151, 118,  84],
        [123,  92,  72]]], dtype=uint8)</pre></div><script>
      (() => {
      const titles = ['show data', 'hide data'];
      let index = 0
      document.querySelector('#id-55111274-862b-469d-9dd8-15b48d3d6fcd button').onclick = (e) => {
        document.querySelector('#id-55111274-862b-469d-9dd8-15b48d3d6fcd').classList.toggle('show_array');
        index = (++index) % 2;
        document.querySelector('#id-55111274-862b-469d-9dd8-15b48d3d6fcd button').textContent = titles[index];
        e.preventDefault();
        e.stopPropagation();
      }
      })();
    </script></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_set</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">train_set</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="n">train_set</span><span class="o">.</span><span class="n">class_to_idx</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([6,
  9,
  9,
  4,
  1,
  1,
  2,
  7,
  8,
  3,
  4,
  7,
  7,
  2,
  9,
  9,
  9,
  3,
  2,
  6,
  4,
  3,
  6,
  6,
  2,
  6,
  3,
  5,
  4,
  0,
  0,
  9,
  1,
  3,
  4,
  0,
  3,
  7,
  3,
  3,
  5,
  2,
  2,
  7,
  1,
  1,
  1,
  2,
  2,
  0,
  9,
  5,
  7,
  9,
  2,
  2,
  5,
  2,
  4,
  3,
  1,
  1,
  8,
  2,
  1,
  1,
  4,
  9,
  7,
  8,
  5,
  9,
  6,
  7,
  3,
  1,
  9,
  0,
  3,
  1,
  3,
  5,
  4,
  5,
  7,
  7,
  4,
  7,
  9,
  4,
  2,
  3,
  8,
  0,
  1,
  6,
  1,
  1,
  4,
  1,
  8,
  3,
  9,
  6,
  6,
  1,
  8,
  5,
  2,
  9,
  9,
  8,
  1,
  7,
  7,
  0,
  0,
  6,
  9,
  1,
  2,
  2,
  9,
  2,
  6,
  6,
  1,
  9,
  5,
  0,
  4,
  7,
  6,
  7,
  1,
  8,
  1,
  1,
  2,
  8,
  1,
  3,
  3,
  6,
  2,
  4,
  9,
  9,
  5,
  4,
  3,
  6,
  7,
  4,
  6,
  8,
  5,
  5,
  4,
  3,
  1,
  8,
  4,
  7,
  6,
  0,
  9,
  5,
  1,
  3,
  8,
  2,
  7,
  5,
  3,
  4,
  1,
  5,
  7,
  0,
  4,
  7,
  5,
  5,
  1,
  0,
  9,
  6,
  9,
  0,
  8,
  7,
  8,
  8,
  2,
  5,
  2,
  3,
  5,
  0,
  6,
  1,
  9,
  3,
  6,
  9,
  1,
  3,
  9,
  6,
  6,
  7,
  1,
  0,
  9,
  5,
  8,
  5,
  2,
  9,
  0,
  8,
  8,
  0,
  6,
  9,
  1,
  1,
  6,
  3,
  7,
  6,
  6,
  0,
  6,
  6,
  1,
  7,
  1,
  5,
  8,
  3,
  6,
  6,
  8,
  6,
  8,
  4,
  6,
  6,
  1,
  3,
  8,
  3,
  4,
  1,
  7,
  1,
  3,
  8,
  5,
  1,
  1,
  4,
  0,
  9,
  3,
  7,
  4,
  9,
  9,
  2,
  4,
  9,
  9,
  1,
  0,
  5,
  9,
  0,
  8,
  2,
  1,
  2,
  0,
  5,
  6,
  3,
  2,
  7,
  8,
  8,
  6,
  0,
  7,
  9,
  4,
  5,
  6,
  4,
  2,
  1,
  1,
  2,
  1,
  5,
  9,
  9,
  0,
  8,
  4,
  1,
  1,
  6,
  3,
  3,
  9,
  0,
  7,
  9,
  7,
  7,
  9,
  1,
  5,
  1,
  6,
  6,
  8,
  7,
  1,
  3,
  0,
  3,
  3,
  2,
  4,
  5,
  7,
  5,
  9,
  0,
  3,
  4,
  0,
  4,
  4,
  6,
  0,
  0,
  6,
  6,
  0,
  8,
  1,
  6,
  2,
  9,
  2,
  5,
  9,
  6,
  7,
  4,
  1,
  8,
  7,
  3,
  6,
  9,
  3,
  0,
  4,
  0,
  5,
  1,
  0,
  3,
  4,
  8,
  5,
  4,
  7,
  2,
  3,
  9,
  7,
  6,
  7,
  1,
  4,
  7,
  0,
  1,
  7,
  3,
  1,
  8,
  4,
  4,
  2,
  0,
  2,
  2,
  0,
  0,
  9,
  0,
  9,
  6,
  8,
  2,
  7,
  7,
  4,
  0,
  3,
  0,
  8,
  9,
  4,
  2,
  7,
  2,
  5,
  2,
  5,
  1,
  9,
  4,
  8,
  5,
  1,
  7,
  4,
  4,
  0,
  6,
  9,
  0,
  7,
  8,
  8,
  9,
  9,
  3,
  3,
  4,
  0,
  4,
  5,
  6,
  6,
  0,
  1,
  0,
  8,
  0,
  4,
  8,
  8,
  1,
  5,
  2,
  6,
  8,
  1,
  0,
  0,
  7,
  7,
  5,
  9,
  6,
  2,
  8,
  3,
  4,
  7,
  3,
  9,
  0,
  1,
  2,
  4,
  8,
  1,
  8,
  6,
  4,
  4,
  5,
  7,
  1,
  3,
  9,
  8,
  0,
  1,
  7,
  5,
  8,
  2,
  8,
  0,
  4,
  1,
  8,
  9,
  8,
  2,
  9,
  9,
  2,
  7,
  5,
  7,
  3,
  8,
  8,
  4,
  4,
  2,
  7,
  1,
  6,
  4,
  0,
  4,
  6,
  9,
  7,
  6,
  2,
  5,
  5,
  1,
  7,
  2,
  2,
  2,
  9,
  5,
  4,
  2,
  7,
  8,
  1,
  3,
  4,
  3,
  7,
  6,
  9,
  8,
  0,
  6,
  0,
  2,
  2,
  2,
  1,
  8,
  4,
  0,
  1,
  8,
  8,
  1,
  5,
  7,
  6,
  4,
  5,
  8,
  7,
  1,
  9,
  1,
  9,
  8,
  4,
  7,
  3,
  8,
  8,
  2,
  6,
  6,
  7,
  1,
  6,
  8,
  1,
  9,
  7,
  8,
  3,
  0,
  1,
  0,
  8,
  8,
  3,
  0,
  0,
  1,
  5,
  0,
  8,
  8,
  7,
  9,
  9,
  0,
  9,
  4,
  1,
  3,
  6,
  6,
  4,
  4,
  7,
  5,
  6,
  0,
  8,
  0,
  3,
  2,
  8,
  4,
  6,
  9,
  9,
  7,
  0,
  3,
  3,
  6,
  7,
  4,
  9,
  1,
  6,
  2,
  7,
  2,
  2,
  0,
  6,
  7,
  5,
  7,
  6,
  8,
  9,
  0,
  9,
  4,
  4,
  7,
  0,
  9,
  4,
  9,
  6,
  9,
  4,
  5,
  7,
  9,
  2,
  4,
  5,
  1,
  4,
  3,
  9,
  6,
  5,
  6,
  9,
  3,
  3,
  5,
  0,
  7,
  2,
  1,
  3,
  6,
  4,
  0,
  0,
  2,
  5,
  0,
  1,
  0,
  2,
  3,
  9,
  8,
  4,
  9,
  8,
  0,
  2,
  6,
  4,
  4,
  0,
  1,
  8,
  8,
  3,
  6,
  9,
  6,
  6,
  7,
  8,
  2,
  4,
  5,
  7,
  6,
  5,
  3,
  0,
  5,
  0,
  5,
  0,
  8,
  2,
  6,
  7,
  3,
  8,
  2,
  1,
  7,
  6,
  7,
  1,
  0,
  9,
  5,
  5,
  0,
  1,
  7,
  6,
  9,
  0,
  4,
  7,
  7,
  1,
  5,
  9,
  4,
  0,
  8,
  5,
  9,
  9,
  6,
  7,
  1,
  8,
  3,
  2,
  3,
  8,
  2,
  2,
  4,
  6,
  0,
  0,
  5,
  3,
  8,
  2,
  3,
  7,
  2,
  9,
  3,
  8,
  7,
  8,
  2,
  7,
  9,
  0,
  2,
  3,
  2,
  2,
  2,
  3,
  3,
  6,
  2,
  3,
  2,
  8,
  0,
  5,
  5,
  1,
  4,
  5,
  6,
  6,
  2,
  7,
  0,
  1,
  7,
  7,
  8,
  2,
  9,
  2,
  2,
  4,
  2,
  1,
  1,
  1,
  6,
  6,
  6,
  5,
  1,
  1,
  7,
  0,
  4,
  3,
  3,
  7,
  1,
  2,
  3,
  5,
  5,
  5,
  6,
  1,
  4,
  3,
  7,
  8,
  8,
  3,
  6,
  6,
  2,
  3,
  0,
  9,
  4,
  3,
  8,
  0,
  0,
  1,
  1,
  5,
  4,
  9,
  3,
  1,
  8,
  9,
  3,
  9,
  9,
  2,
  9,
  4,
  8,
  2,
  9,
  8,
  8,
  1,
  5,
  3,
  6,
  8,
  7,
  6,
  9,
  8,
  0,
  6,
  4,
  0,
  0,
  2,
  5,
  8,
  2,
  0,
  2,
  7,
  6,
  9,
  7,
  1,
  5,
  5,
  6,
  6,
  3,
  6,
  2,
  4,
  7,
  0,
  5,
  6,
  4,
  6,
  5,
  2,
  4,
  6,
  1,
  6,
  0,
  4,
  0,
  3,
  1,
  8,
  5,
  4,
  4,
  1,
  7,
  3,
  9,
  4,
  7,
  9,
  7,
  3,
  7,
  2,
  8,
  4,
  6,
  6,
  1,
  2,
  9,
  0,
  4,
  8,
  7,
  3,
  9,
  8,
  7,
  7,
  0,
  2,
  4,
  1,
  1,
  4,
  1,
  5,
  4,
  0,
  5,
  6,
  2,
  8,
  5,
  0,
  2,
  1,
  3,
  5,
  7,
  3,
  5,
  1,
  3,
  5,
  ...],
 [&#39;airplane&#39;,
  &#39;automobile&#39;,
  &#39;bird&#39;,
  &#39;cat&#39;,
  &#39;deer&#39;,
  &#39;dog&#39;,
  &#39;frog&#39;,
  &#39;horse&#39;,
  &#39;ship&#39;,
  &#39;truck&#39;],
 {&#39;airplane&#39;: 0,
  &#39;automobile&#39;: 1,
  &#39;bird&#39;: 2,
  &#39;cat&#39;: 3,
  &#39;deer&#39;: 4,
  &#39;dog&#39;: 5,
  &#39;frog&#39;: 6,
  &#39;horse&#39;: 7,
  &#39;ship&#39;: 8,
  &#39;truck&#39;: 9})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_iter</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">train_iter</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-width:800px; border: 1px solid var(--colab-border-color);"><style>
      pre.function-repr-contents {
        overflow-x: auto;
        padding: 8px 12px;
        max-height: 500px;
      }

      pre.function-repr-contents.function-repr-contents-collapsed {
        cursor: pointer;
        max-height: 100px;
      }
    </style>
    <pre style="white-space: initial; background:
         var(--colab-secondary-surface-color); padding: 8px 12px;
         border-bottom: 1px solid var(--colab-border-color);"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;)</pre><pre class="function-repr-contents function-repr-contents-collapsed" style=""><a class="filepath" style="display:none" href="#">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</a>Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.

The :class:`~torch.utils.data.DataLoader` supports both map-style and
iterable-style datasets with single- or multi-process loading, customizing
loading order and optional automatic batching (collation) and memory pinning.

See :py:mod:`torch.utils.data` documentation page for more details.

Args:
    dataset (Dataset): dataset from which to load the data.
    batch_size (int, optional): how many samples per batch to load
        (default: ``1``).
    shuffle (bool, optional): set to ``True`` to have the data reshuffled
        at every epoch (default: ``False``).
    sampler (Sampler or Iterable, optional): defines the strategy to draw
        samples from the dataset. Can be any ``Iterable`` with ``__len__``
        implemented. If specified, :attr:`shuffle` must not be specified.
    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but
        returns a batch of indices at a time. Mutually exclusive with
        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,
        and :attr:`drop_last`.
    num_workers (int, optional): how many subprocesses to use for data
        loading. ``0`` means that the data will be loaded in the main process.
        (default: ``0``)
    collate_fn (Callable, optional): merges a list of samples to form a
        mini-batch of Tensor(s).  Used when using batched loading from a
        map-style dataset.
    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors
        into device/CUDA pinned memory before returning them.  If your data elements
        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,
        see the example below.
    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,
        if the dataset size is not divisible by the batch size. If ``False`` and
        the size of dataset is not divisible by the batch size, then the last batch
        will be smaller. (default: ``False``)
    timeout (numeric, optional): if positive, the timeout value for collecting a batch
        from workers. Should always be non-negative. (default: ``0``)
    worker_init_fn (Callable, optional): If not ``None``, this will be called on each
        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as
        input, after seeding and before data loading. (default: ``None``)
    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If
        ``None``, the default `multiprocessing context`_ of your operating system will
        be used. (default: ``None``)
    generator (torch.Generator, optional): If not ``None``, this RNG will be used
        by RandomSampler to generate random indexes and multiprocessing to generate
        ``base_seed`` for workers. (default: ``None``)
    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded
        in advance by each worker. ``2`` means there will be a total of
        2 * num_workers batches prefetched across all workers. (default value depends
        on the set value for num_workers. If value of num_workers=0 default is ``None``.
        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).
    persistent_workers (bool, optional): If ``True``, the data loader will not shut down
        the worker processes after a dataset has been consumed once. This allows to
        maintain the workers `Dataset` instances alive. (default: ``False``)
    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is
        ``True``.


.. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`
             cannot be an unpicklable object, e.g., a lambda function. See
             :ref:`multiprocessing-best-practices` on more details related
             to multiprocessing in PyTorch.

.. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.
             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,
             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper
             rounding depending on :attr:`drop_last`, regardless of multi-process loading
             configurations. This represents the best guess PyTorch can make because PyTorch
             trusts user :attr:`dataset` code in correctly handling multi-process
             loading to avoid duplicate data.

             However, if sharding results in multiple workers having incomplete last batches,
             this estimate can still be inaccurate, because (1) an otherwise complete batch can
             be broken into multiple ones and (2) more than one batch worth of samples can be
             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such
             cases in general.

             See `Dataset Types`_ for more details on these two types of datasets and how
             :class:`~torch.utils.data.IterableDataset` interacts with
             `Multi-process data loading`_.

.. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and
             :ref:`data-loading-randomness` notes for random seed related questions.

.. _multiprocessing context:
    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>
      <script>
      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {
        for (const element of document.querySelectorAll('.filepath')) {
          element.style.display = 'block'
          element.onclick = (event) => {
            event.preventDefault();
            event.stopPropagation();
            google.colab.files.view(element.textContent, 125);
          };
        }
      }
      for (const element of document.querySelectorAll('.function-repr-contents')) {
        element.onclick = (event) => {
          event.preventDefault();
          event.stopPropagation();
          element.classList.toggle('function-repr-contents-collapsed');
        };
      }
      </script>
      </div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">features</span><span class="p">,</span><span class="n">labels</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
  <span class="k">break</span> <span class="c1"># on first 100</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          ...,
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],


        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          ...,
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],


        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          ...,
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],


        ...,


        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          ...,
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],


        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          ...,
          [-1.0000, -0.9922, -1.0000,  ..., -1.0000, -0.9843, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],


        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          ...,
          [-1.0000, -0.9922, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## nn.Linear(in,out)</span>
<span class="c1"># nn.Conv2d(in_channels,out_channels,kernel_size)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_iter</span><span class="p">)</span>
<span class="n">feat</span><span class="p">,</span> <span class="n">lab</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">feat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 28, 28])
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\( H_0 = \frac{H+2P-K}{S} + 1 \)</span>, <span class="math notranslate nohighlight">\(W_0 = \frac{W+2P-K}{S} + 1 \)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([6, 1, 5, 5])
</pre></div>
</div>
</div>
</div>
<p>6 kernels of size <span class="math notranslate nohighlight">\(1 * 5*5\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([6, 24, 24])
</pre></div>
</div>
</div>
</div>
<p>(N,C,H,W)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pool1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">pool1</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="n">x2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([6, 12, 12])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="mi">4</span><span class="o">*</span><span class="mi">4</span> <span class="p">,</span> <span class="mi">80</span><span class="p">)</span>    <span class="c1">#6*4*4 how?</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># classification problem for 10 classes</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="o">*</span><span class="mi">4</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>  <span class="c1">#why view how (-1,6*4*4)?</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="n">Model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">feat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.2060,  0.2773, -0.0885,  0.1114, -0.1032, -0.0211,  0.2460,  0.0767,
         -0.0650, -0.0098]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>Training</p>
<ul class="simple">
<li><p>Define Criterion</p></li>
<li><p>Optimizer</p></li>
</ul>
<hr class="docutils" />
<ol class="arabic simple">
<li><p>zero_grad()</p></li>
<li><p>Forward Pass</p></li>
<li><p>Loss compute</p></li>
<li><p>Backprop</p></li>
<li><p>Updation</p></li>
</ol>
<ul class="simple">
<li><p>1 epoch = pass through entire dataset</p></li>
<li><p>1 iteration = pass through 1 batch</p>
<ul>
<li><p>total points = 60000</p></li>
<li><p>batch size = 100</p></li>
<li><p>batches = 600</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">Model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
  <span class="n">total_correct_pts</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">ls</span> <span class="o">=</span> <span class="n">Loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">ls</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">corr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">total_correct</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
    <span class="n">total_correct_pts</span> <span class="o">+=</span> <span class="n">total_correct</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">total_correct_pts</span><span class="o">/</span><span class="mi">60000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.1011)
tensor(0.1000)
tensor(0.0994)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="s1">&#39;.data&#39;</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">download</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_iter</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">test_output</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_corr</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">test_iter</span><span class="p">:</span>
  <span class="n">feat</span><span class="p">,</span> <span class="n">lab</span> <span class="o">=</span> <span class="n">data</span>
  <span class="n">test_out</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>

  <span class="n">corr_classes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_out</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">lab</span><span class="p">)</span>
  <span class="n">tcd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">corr_classes</span><span class="p">)</span>
  <span class="n">test_corr</span><span class="o">+=</span> <span class="n">tcd</span>

<span class="nb">print</span><span class="p">(</span><span class="n">test_corr</span><span class="o">/</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-67-e62434cee023&gt;</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">test_corr</span> <span class="o">=</span> <span class="mi">0</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">test_iter</span><span class="p">:</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>   <span class="n">feat</span><span class="p">,</span> <span class="n">lab</span> <span class="o">=</span> <span class="n">data</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>   <span class="n">test_out</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> 

<span class="nn">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</span> in <span class="ni">__next__</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">628</span>                 <span class="c1"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>
<span class="g g-Whitespace">    </span><span class="mi">629</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>  <span class="c1"># type: ignore[call-arg]</span>
<span class="ne">--&gt; </span><span class="mi">630</span>             <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_next_data</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">631</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_num_yielded</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="g g-Whitespace">    </span><span class="mi">632</span>             <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset_kind</span> <span class="o">==</span> <span class="n">_DatasetKind</span><span class="o">.</span><span class="n">Iterable</span> <span class="ow">and</span> \

<span class="nn">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</span> in <span class="ni">_next_data</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">671</span>     <span class="k">def</span> <span class="nf">_next_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">672</span>         <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_next_index</span><span class="p">()</span>  <span class="c1"># may raise StopIteration</span>
<span class="ne">--&gt; </span><span class="mi">673</span>         <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset_fetcher</span><span class="o">.</span><span class="n">fetch</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>  <span class="c1"># may raise StopIteration</span>
<span class="g g-Whitespace">    </span><span class="mi">674</span>         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pin_memory</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">675</span>             <span class="n">data</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">pin_memory</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pin_memory_device</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py</span> in <span class="ni">fetch</span><span class="nt">(self, possibly_batched_index)</span>
<span class="g g-Whitespace">     </span><span class="mi">53</span>         <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span>             <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">possibly_batched_index</span><span class="p">]</span>
<span class="ne">---&gt; </span><span class="mi">55</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py</span> in <span class="ni">default_collate</span><span class="nt">(batch)</span>
<span class="g g-Whitespace">    </span><span class="mi">315</span>         <span class="o">&gt;&gt;&gt;</span> <span class="n">default_collate</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Handle `CustomType` automatically</span>
<span class="g g-Whitespace">    </span><span class="mi">316</span>     <span class="s2">&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">317</span><span class="s2">     return collate(batch, collate_fn_map=default_collate_fn_map)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py</span> in <span class="ni">collate</span><span class="nt">(batch, collate_fn_map)</span>
<span class="g g-Whitespace">    </span><span class="mi">172</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">173</span><span class="s2">         if isinstance(elem, tuple):</span>
<span class="ne">--&gt; </span><span class="mi">174</span><span class="s2">             return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.</span>
<span class="g g-Whitespace">    </span><span class="mi">175</span><span class="s2">         else:</span>
<span class="g g-Whitespace">    </span><span class="mi">176</span><span class="s2">             try:</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">    </span><span class="mi">172</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">173</span><span class="s2">         if isinstance(elem, tuple):</span>
<span class="ne">--&gt; </span><span class="mi">174</span><span class="s2">             return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.</span>
<span class="g g-Whitespace">    </span><span class="mi">175</span><span class="s2">         else:</span>
<span class="g g-Whitespace">    </span><span class="mi">176</span><span class="s2">             try:</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py</span> in <span class="ni">collate</span><span class="nt">(batch, collate_fn_map)</span>
<span class="g g-Whitespace">    </span><span class="mi">190</span><span class="s2">                 return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]</span>
<span class="g g-Whitespace">    </span><span class="mi">191</span><span class="s2"> </span>
<span class="ne">--&gt; </span><span class="mi">192</span><span class="s2">     raise TypeError(default_collate_err_msg_format.format(elem_type))</span>
<span class="g g-Whitespace">    </span><span class="mi">193</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">194</span><span class="s2"> </span>

<span class="ne">TypeError</span>: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found &lt;class &#39;PIL.Image.Image&#39;&gt;
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Day2_DL_Workshop.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Artificial Neural Networks</p>
      </div>
    </a>
    <a class="right-next"
       href="Day4_DL_Workshop.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">RNN</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yash Mishra
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>