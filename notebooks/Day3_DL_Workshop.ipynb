{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORoZWo+rXPwoj0n9w3MKhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-y9/Deep-Learning-using-PyTorch/blob/main/Day3_DL_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN\n",
        "The movie was fantastic\n",
        "- **seq lenghth** = 4\n",
        "- **input/embedded dimension** = 5(state vector dimensions)\n",
        "- **hidden dimension**\n",
        "- **Linear layer** for final output\n",
        "$ h_0 ->h_1->h_2->h_3->h_4 $\n",
        "$  $"
      ],
      "metadata": {
        "id": "Ybk400uZrrDQ"
      }
    },
  {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "VUBVgbjupy7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJAjJrVZnNfQ"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# efficient in creating batches and in the process of itrating tohrough batches during"
      ],
      "metadata": {
        "id": "0DK066YZwEoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(datasets)\n",
        "help(datasets.FashionMNIST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nFEBLWxips1K",
        "outputId": "ba10cb81-9f03-42ff-8d75-4d546d32deb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class FashionMNIST in module torchvision.datasets.mnist:\n",
            "\n",
            "class FashionMNIST(MNIST)\n",
            " |  FashionMNIST(root: Union[str, pathlib.Path], train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
            " |  \n",
            " |  `Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
            " |  \n",
            " |  Args:\n",
            " |      root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
            " |          and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
            " |      train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
            " |          otherwise from ``t10k-images-idx3-ubyte``.\n",
            " |      download (bool, optional): If True, downloads the dataset from the internet and\n",
            " |          puts it in root directory. If dataset is already downloaded, it is not\n",
            " |          downloaded again.\n",
            " |      transform (callable, optional): A function/transform that  takes in a PIL image\n",
            " |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
            " |      target_transform (callable, optional): A function/transform that takes in the\n",
            " |          target and transforms it.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      FashionMNIST\n",
            " |      MNIST\n",
            " |      torchvision.datasets.vision.VisionDataset\n",
            " |      torch.utils.data.dataset.Dataset\n",
            " |      typing.Generic\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __annotations__ = {}\n",
            " |  \n",
            " |  __parameters__ = ()\n",
            " |  \n",
            " |  classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'San...\n",
            " |  \n",
            " |  mirrors = ['http://fashion-mnist.s3-website.eu-central-1.amazonaws.com...\n",
            " |  \n",
            " |  resources = [('train-images-idx3-ubyte.gz', '8d4fb7e6c68d591d4c3dfef9e...\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from MNIST:\n",
            " |  \n",
            " |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
            " |      Args:\n",
            " |          index (int): Index\n",
            " |      \n",
            " |      Returns:\n",
            " |          tuple: (image, target) where target is index of the target class.\n",
            " |  \n",
            " |  __init__(self, root: Union[str, pathlib.Path], train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __len__(self) -> int\n",
            " |  \n",
            " |  download(self) -> None\n",
            " |      Download the MNIST data if it doesn't exist already.\n",
            " |  \n",
            " |  extra_repr(self) -> str\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from MNIST:\n",
            " |  \n",
            " |  class_to_idx\n",
            " |  \n",
            " |  processed_folder\n",
            " |  \n",
            " |  raw_folder\n",
            " |  \n",
            " |  test_data\n",
            " |  \n",
            " |  test_labels\n",
            " |  \n",
            " |  train_data\n",
            " |  \n",
            " |  train_labels\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from MNIST:\n",
            " |  \n",
            " |  test_file = 'test.pt'\n",
            " |  \n",
            " |  training_file = 'training.pt'\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
            " |  \n",
            " |  __repr__(self) -> str\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
            " |  \n",
            " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
            " |  \n",
            " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from typing.Generic:\n",
            " |  \n",
            " |  __class_getitem__(params) from builtins.type\n",
            " |  \n",
            " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
            " |      This method is called when a class is subclassed.\n",
            " |      \n",
            " |      The default implementation does nothing. It may be\n",
            " |      overridden to extend subclasses.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST('.data', train = True, download = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bKK8R6xMp1ZF",
        "outputId": "72c50b54-9cfb-4302-b72a-1c517c086747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to .data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 17215704.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/FashionMNIST/raw/train-images-idx3-ubyte.gz to .data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to .data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 274193.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to .data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to .data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4937716.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to .data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to .data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 3161850.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to .data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH7VPSBpp_oj",
        "outputId": "bf87c7e7-8d0c-4bf0-d426-53cf2e56fc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape, train_data.targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qas_tJhvqOKm",
        "outputId": "7c7bb88f-04cc-4614-d209-4bfce162905b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([60000]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{train_data.classes},\\n {train_data.class_to_idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TImaQnXQqwHA",
        "outputId": "4b05cbf5-3f1f-4d59-dc6a-7e92196a4b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'],\n",
            " {'T-shirt/top': 0, 'Trouser': 1, 'Pullover': 2, 'Dress': 3, 'Coat': 4, 'Sandal': 5, 'Shirt': 6, 'Sneaker': 7, 'Bag': 8, 'Ankle boot': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxeOCHWCqz6C",
        "outputId": "6becbb79-8e08-4342-8fff-2b4af7c968ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28>, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "evIdyt7isFYc",
        "outputId": "6c56db7c-1f0d-4fd2-b853-5b40bda74027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACBUlEQVR4nLXSz0tUURQH8O+597373rx545g6NmNJY6TlJgozEsKFZGCrkDBoVdGmdf9BiwJ3bVr1PwhBUbQfJQcKjWZRTsjo0KDpDPV+eN+997WK0Z2bvtsPfM+Bc4D/HwJycwBZAEAE6zAyfe5RFMQfFYiRAj+CXM/c2HK82VetVMM34RGUmCxz9v7yYnW9dnWyskyHR6azi72Jwep3ScVk9c7LLhKQrpRBSiI2n76puZFT3doUwH4pcmw/zpjrU2zw3dFt4XEWdvbKhpinzTBYt5bDH4qlLYO8cbKBWHOudDHluFtiLrLD0kmM2//6q9VFS+JLLDxv9GzMPV9v3XuzYgHEGSUGCngbRCLd4W6CxPCLHTDwVMkDA0y/qEa/lFFBoF2EEME8CAD6hsZK8+djlmSatuiXXsWfNh27NU6Yelro1bytPElRbaGaO1FGPfc7zPg9HvHlIaVD8AjID9y/+bgZ/6iP9ks7J/QZevh8w/cd2PlGs8CKt92R7MQEk0yA7GtWq9ETN3zRs7fpR7FaWi/3yXaipW1IjFnbaSM70N7dsRzbzbHd8aCx7+wmKskUO5esz0sPmvXYF67gBzoNfxptxb5stxM10iLg1pOTO23NhcUptW1hE6gFYYprC8QMMPNsMM+4pamVbps/HGkSsg+1Cv4d+0Jh//Sm3DjGix4rfwFoJNh2/0cDFgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "jsWEIU6nsLa4",
        "outputId": "0844b468-6165-4a14-8923-25ad44b97340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b901ad7cf70>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NVa5c8IwrPAG",
        "outputId": "d11957bf-8daf-4a3b-eed2-addafd95a15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AugMix',\n",
              " 'AutoAugment',\n",
              " 'AutoAugmentPolicy',\n",
              " 'CenterCrop',\n",
              " 'ColorJitter',\n",
              " 'Compose',\n",
              " 'ConvertImageDtype',\n",
              " 'ElasticTransform',\n",
              " 'FiveCrop',\n",
              " 'GaussianBlur',\n",
              " 'Grayscale',\n",
              " 'InterpolationMode',\n",
              " 'Lambda',\n",
              " 'LinearTransformation',\n",
              " 'Normalize',\n",
              " 'PILToTensor',\n",
              " 'Pad',\n",
              " 'RandAugment',\n",
              " 'RandomAdjustSharpness',\n",
              " 'RandomAffine',\n",
              " 'RandomApply',\n",
              " 'RandomAutocontrast',\n",
              " 'RandomChoice',\n",
              " 'RandomCrop',\n",
              " 'RandomEqualize',\n",
              " 'RandomErasing',\n",
              " 'RandomGrayscale',\n",
              " 'RandomHorizontalFlip',\n",
              " 'RandomInvert',\n",
              " 'RandomOrder',\n",
              " 'RandomPerspective',\n",
              " 'RandomPosterize',\n",
              " 'RandomResizedCrop',\n",
              " 'RandomRotation',\n",
              " 'RandomSolarize',\n",
              " 'RandomVerticalFlip',\n",
              " 'Resize',\n",
              " 'TenCrop',\n",
              " 'ToPILImage',\n",
              " 'ToTensor',\n",
              " 'TrivialAugmentWide',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_functional_pil',\n",
              " '_functional_tensor',\n",
              " '_presets',\n",
              " 'autoaugment',\n",
              " 'functional',\n",
              " 'transforms']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape #shows channel = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FfIdiKispxW",
        "outputId": "0d88e431-2d1e-4ca7-bad9-75c84e790031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ToTensor()**\n",
        "\n",
        "Converts images into tensor and then standardise dataset (PIL)"
      ],
      "metadata": {
        "id": "XyG5bBZKtgXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "transform1 = transforms.Compose((transforms.ToTensor(), transforms.Normalize((0.5), (0.5))))"
      ],
      "metadata": {
        "id": "dfd0HufnronV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST('.data', train = True, transform = transform1)"
      ],
      "metadata": {
        "id": "E4MnOc4ftEy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0] # but.dat[0][0] does not change"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yzagua9TtRzc",
        "outputId": "722ebecf-2fd0-4a0a-cf61-d00d01a95473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000,\n",
              "           -1.0000, -0.8980, -0.4275, -1.0000, -1.0000, -0.9922, -0.9686,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -0.9922, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -1.0000,\n",
              "           -0.7176,  0.0667, -0.0039, -0.5137, -0.5765, -1.0000, -1.0000,\n",
              "           -1.0000, -0.9922, -0.9765, -0.9686, -1.0000, -1.0000, -0.9765],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529, -1.0000,\n",
              "           -0.2000,  0.6000,  0.3804,  0.0510,  0.1294, -0.0353, -0.8196,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9059, -0.9216, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "            0.2157,  0.8510,  0.6235,  0.3961, -0.1608,  0.2235,  0.2627,\n",
              "           -0.1451, -0.4980, -0.8196, -0.3961,  0.0196, -0.4353, -0.8824],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9922, -1.0000, -0.4588,\n",
              "            0.6235,  0.7490,  0.7098,  0.6941,  0.6941,  0.2784, -0.0039,\n",
              "           -0.0510, -0.0431,  0.1451,  0.1059, -0.3098,  0.3490, -0.4824],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -0.9922, -0.9922, -0.9922, -1.0000,  0.5686,\n",
              "            0.8196,  0.8196,  0.8275,  0.7961,  0.7490,  0.7490,  0.6863,\n",
              "            0.6706,  0.2863, -0.0039, -0.0353,  0.5373,  0.7961, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.4353,\n",
              "            0.7647,  0.6941,  0.7490,  0.7882,  0.8431,  0.7804,  0.7569,\n",
              "            0.7412,  0.7569,  0.7333,  0.7490,  0.9216,  0.3569, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5137,\n",
              "            0.7882,  0.7098,  0.6706,  0.5529,  0.4118,  0.6627,  0.6471,\n",
              "            0.6549,  0.6706,  0.7490,  0.7255,  0.9059,  0.5843, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -0.9922, -0.9765, -1.0000, -0.9059,  0.7176,\n",
              "            0.7255,  0.6627,  0.7098,  0.5059,  0.3255,  0.7804,  0.6314,\n",
              "            0.7098,  0.7569,  0.6627,  0.7725,  0.5451,  0.6392, -0.5922],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -0.9529, -1.0000, -0.2235,  0.9137,\n",
              "            0.7412,  0.7255,  0.7098,  0.5922,  0.5529,  0.7333,  0.6863,\n",
              "            0.6706,  0.7412,  0.7255,  0.9216, -0.0667,  0.3098, -0.5608],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -0.9686, -1.0000, -1.0000, -0.5686,  0.8510,\n",
              "            0.7882,  0.8039,  0.7882,  0.8824,  0.8196,  0.6706,  0.7098,\n",
              "            0.7490,  0.8353,  0.7020,  0.7020,  0.6392, -0.2784, -1.0000],\n",
              "          [-1.0000, -1.0000, -0.9922, -0.9686, -0.9529, -0.9451, -0.9843,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8588,  0.7725,\n",
              "            0.7020,  0.7490,  0.7412,  0.7176,  0.7412,  0.7333,  0.6941,\n",
              "            0.7490,  0.7961,  0.6863,  0.7098,  1.0000, -0.3961, -1.0000],\n",
              "          [-1.0000, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -0.5137,  0.1373,  0.6000,  0.7882,  0.6235,\n",
              "            0.6706,  0.7333,  0.7098,  0.6314,  0.6549,  0.7098,  0.7569,\n",
              "            0.7490,  0.7176,  0.6863,  0.7569,  0.9137,  0.2471, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.8588, -0.6549, -0.3569,\n",
              "           -0.1608,  0.4824,  0.7882,  0.7255,  0.7412,  0.7020,  0.7725,\n",
              "            0.5686,  0.6078,  0.6549,  0.8039,  0.7569,  0.8353,  0.3804,\n",
              "            0.4745,  0.9608,  0.9451,  0.8275,  0.8667,  0.6863, -1.0000],\n",
              "          [-1.0000, -0.5529,  0.4667,  0.6314,  0.7569,  0.7333,  0.7569,\n",
              "            0.6314,  0.6000,  0.6784,  0.6314,  0.6392,  0.5686,  0.2471,\n",
              "            0.9216,  0.5137,  0.6157,  0.7490,  1.0000,  1.0000,  0.7333,\n",
              "            0.8353,  0.7333,  0.6549,  0.7255,  0.8196,  0.9294, -1.0000],\n",
              "          [-0.9765,  0.5843,  0.7882,  0.7569,  0.7333,  0.6549,  0.6549,\n",
              "            0.6784,  0.6078,  0.6078,  0.6078,  0.7255,  0.8824, -0.3725,\n",
              "            0.1765,  1.0000,  0.7961,  0.7333,  0.4745,  0.2078,  0.4980,\n",
              "            0.6471,  0.6000,  0.6392,  0.7412,  0.7882,  0.7647, -1.0000],\n",
              "          [-0.2314,  0.8275,  0.5529,  0.6471,  0.7412,  0.7961,  0.7961,\n",
              "            0.8353,  0.9529,  0.7255,  0.5216,  0.6863,  0.7020,  0.8902,\n",
              "           -0.4902, -0.4275, -0.1686, -0.0824,  0.3176,  0.7176,  0.7333,\n",
              "            0.6863,  0.7020,  0.7490,  0.7490,  0.7569,  0.7961, -0.7725],\n",
              "          [-0.4118,  0.6000,  0.6627,  0.6000,  0.5137,  0.6078,  0.6549,\n",
              "            0.7647,  0.6941,  0.4510,  0.5451,  0.6157,  0.5529,  0.6706,\n",
              "            0.8824,  0.5294,  0.7804,  0.9216,  0.8745,  0.7490,  0.7098,\n",
              "            0.6627,  0.6392,  0.7412,  0.7255,  0.7333,  0.8039, -0.4745],\n",
              "          [-0.6235,  0.5922,  0.4353,  0.5216,  0.6706,  0.5451,  0.4510,\n",
              "            0.4902,  0.5216,  0.5059,  0.5843,  0.6784,  0.7176,  0.7333,\n",
              "            0.7255,  0.8510,  0.7647,  0.6941,  0.5608,  0.6157,  0.4588,\n",
              "            0.4196,  0.3882,  0.3490,  0.4196,  0.6078,  0.6157, -0.0980],\n",
              "          [-1.0000, -0.0431,  0.7176,  0.5137,  0.4039,  0.3412,  0.4353,\n",
              "            0.5373,  0.6000,  0.6471,  0.6706,  0.6235,  0.6549,  0.6471,\n",
              "            0.5686,  0.5373,  0.5216,  0.4980,  0.5294,  0.4980,  0.5529,\n",
              "            0.5059,  0.3804,  0.2235,  0.3098,  0.3882,  0.6471, -0.2784],\n",
              "          [-1.0000, -1.0000, -0.4196,  0.4824,  0.6627,  0.4980,  0.3725,\n",
              "            0.3490,  0.3725,  0.4196,  0.4510,  0.4745,  0.4824,  0.4745,\n",
              "            0.5137,  0.5529,  0.6000,  0.6392,  0.6471,  0.6471,  0.6549,\n",
              "            0.4745,  0.4745,  0.5216,  0.5059,  0.6941,  0.3333, -1.0000],\n",
              "          [-0.9843, -1.0000, -1.0000, -1.0000, -0.4824,  0.5686,  0.7412,\n",
              "            0.8588,  0.8745,  0.8980,  0.9294,  0.9059,  0.9137,  0.7333,\n",
              "            0.7255,  0.5137,  0.4980,  0.4039,  0.4275,  0.4275,  0.4196,\n",
              "            0.3804,  0.3020,  0.3176, -0.2235, -0.5451, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.6863, -0.5216, -0.6549, -0.4353, -0.6784, -0.7255, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform2 = transforms.Compose((transforms.ToTensor, transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))))"
      ],
      "metadata": {
        "id": "wkWkSfFwvCri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets.CIFAR10('.data', train = True, transform = transform2 )# download = True)"
      ],
      "metadata": {
        "id": "TVFfpggZtUng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.data.shape #3 channels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vltuRR5Iu0I4",
        "outputId": "782f290c-9ef4-45b8-f43f-e2f8b114284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "D72wvb5Eu5qq",
        "outputId": "f541ce52-5de4-4c84-895d-83ab0a7414f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-55111274-862b-469d-9dd8-15b48d3d6fcd\" class=\"ndarray_repr\"><pre>ndarray (32, 32, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-55111274-862b-469d-9dd8-15b48d3d6fcd button').onclick = (e) => {\n",
              "        document.querySelector('#id-55111274-862b-469d-9dd8-15b48d3d6fcd').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-55111274-862b-469d-9dd8-15b48d3d6fcd button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "id": "jPgxLlnowaQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.targets, train_set.classes, train_set.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yZH1wWuIvqga",
        "outputId": "39ef98ac-ab97-4fc0-b9d0-d0c9791fbf64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([6,\n",
              "  9,\n",
              "  9,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  7,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  7,\n",
              "  7,\n",
              "  2,\n",
              "  9,\n",
              "  9,\n",
              "  9,\n",
              "  3,\n",
              "  2,\n",
              "  6,\n",
              "  4,\n",
              "  3,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  6,\n",
              "  3,\n",
              "  5,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  9,\n",
              "  1,\n",
              "  3,\n",
              "  4,\n",
              "  0,\n",
              "  3,\n",
              "  7,\n",
              "  3,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  7,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  9,\n",
              "  5,\n",
              "  7,\n",
              "  9,\n",
              "  2,\n",
              "  2,\n",
              "  5,\n",
              "  2,\n",
              "  4,\n",
              "  3,\n",
              "  1,\n",
              "  1,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  4,\n",
              "  9,\n",
              "  7,\n",
              "  8,\n",
              "  5,\n",
              "  9,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  1,\n",
              "  9,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  5,\n",
              "  4,\n",
              "  5,\n",
              "  7,\n",
              "  7,\n",
              "  4,\n",
              "  7,\n",
              "  9,\n",
              "  4,\n",
              "  2,\n",
              "  3,\n",
              "  8,\n",
              "  0,\n",
              "  1,\n",
              "  6,\n",
              "  1,\n",
              "  1,\n",
              "  4,\n",
              "  1,\n",
              "  8,\n",
              "  3,\n",
              "  9,\n",
              "  6,\n",
              "  6,\n",
              "  1,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  9,\n",
              "  9,\n",
              "  8,\n",
              "  1,\n",
              "  7,\n",
              "  7,\n",
              "  0,\n",
              "  0,\n",
              "  6,\n",
              "  9,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  9,\n",
              "  2,\n",
              "  6,\n",
              "  6,\n",
              "  1,\n",
              "  9,\n",
              "  5,\n",
              "  0,\n",
              "  4,\n",
              "  7,\n",
              "  6,\n",
              "  7,\n",
              "  1,\n",
              "  8,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  8,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  6,\n",
              "  2,\n",
              "  4,\n",
              "  9,\n",
              "  9,\n",
              "  5,\n",
              "  4,\n",
              "  3,\n",
              "  6,\n",
              "  7,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  5,\n",
              "  5,\n",
              "  4,\n",
              "  3,\n",
              "  1,\n",
              "  8,\n",
              "  4,\n",
              "  7,\n",
              "  6,\n",
              "  0,\n",
              "  9,\n",
              "  5,\n",
              "  1,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  7,\n",
              "  5,\n",
              "  3,\n",
              "  4,\n",
              "  1,\n",
              "  5,\n",
              "  7,\n",
              "  0,\n",
              "  4,\n",
              "  7,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  6,\n",
              "  9,\n",
              "  0,\n",
              "  8,\n",
              "  7,\n",
              "  8,\n",
              "  8,\n",
              "  2,\n",
              "  5,\n",
              "  2,\n",
              "  3,\n",
              "  5,\n",
              "  0,\n",
              "  6,\n",
              "  1,\n",
              "  9,\n",
              "  3,\n",
              "  6,\n",
              "  9,\n",
              "  1,\n",
              "  3,\n",
              "  9,\n",
              "  6,\n",
              "  6,\n",
              "  7,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  9,\n",
              "  0,\n",
              "  8,\n",
              "  8,\n",
              "  0,\n",
              "  6,\n",
              "  9,\n",
              "  1,\n",
              "  1,\n",
              "  6,\n",
              "  3,\n",
              "  7,\n",
              "  6,\n",
              "  6,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  1,\n",
              "  7,\n",
              "  1,\n",
              "  5,\n",
              "  8,\n",
              "  3,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  6,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  6,\n",
              "  1,\n",
              "  3,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  1,\n",
              "  3,\n",
              "  8,\n",
              "  5,\n",
              "  1,\n",
              "  1,\n",
              "  4,\n",
              "  0,\n",
              "  9,\n",
              "  3,\n",
              "  7,\n",
              "  4,\n",
              "  9,\n",
              "  9,\n",
              "  2,\n",
              "  4,\n",
              "  9,\n",
              "  9,\n",
              "  1,\n",
              "  0,\n",
              "  5,\n",
              "  9,\n",
              "  0,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  3,\n",
              "  2,\n",
              "  7,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  0,\n",
              "  7,\n",
              "  9,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  4,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  5,\n",
              "  9,\n",
              "  9,\n",
              "  0,\n",
              "  8,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  6,\n",
              "  3,\n",
              "  3,\n",
              "  9,\n",
              "  0,\n",
              "  7,\n",
              "  9,\n",
              "  7,\n",
              "  7,\n",
              "  9,\n",
              "  1,\n",
              "  5,\n",
              "  1,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  7,\n",
              "  1,\n",
              "  3,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  7,\n",
              "  5,\n",
              "  9,\n",
              "  0,\n",
              "  3,\n",
              "  4,\n",
              "  0,\n",
              "  4,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  9,\n",
              "  2,\n",
              "  5,\n",
              "  9,\n",
              "  6,\n",
              "  7,\n",
              "  4,\n",
              "  1,\n",
              "  8,\n",
              "  7,\n",
              "  3,\n",
              "  6,\n",
              "  9,\n",
              "  3,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  5,\n",
              "  1,\n",
              "  0,\n",
              "  3,\n",
              "  4,\n",
              "  8,\n",
              "  5,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  3,\n",
              "  9,\n",
              "  7,\n",
              "  6,\n",
              "  7,\n",
              "  1,\n",
              "  4,\n",
              "  7,\n",
              "  0,\n",
              "  1,\n",
              "  7,\n",
              "  3,\n",
              "  1,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  9,\n",
              "  0,\n",
              "  9,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  7,\n",
              "  7,\n",
              "  4,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  8,\n",
              "  9,\n",
              "  4,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  2,\n",
              "  5,\n",
              "  1,\n",
              "  9,\n",
              "  4,\n",
              "  8,\n",
              "  5,\n",
              "  1,\n",
              "  7,\n",
              "  4,\n",
              "  4,\n",
              "  0,\n",
              "  6,\n",
              "  9,\n",
              "  0,\n",
              "  7,\n",
              "  8,\n",
              "  8,\n",
              "  9,\n",
              "  9,\n",
              "  3,\n",
              "  3,\n",
              "  4,\n",
              "  0,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  6,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  8,\n",
              "  8,\n",
              "  1,\n",
              "  5,\n",
              "  2,\n",
              "  6,\n",
              "  8,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  7,\n",
              "  7,\n",
              "  5,\n",
              "  9,\n",
              "  6,\n",
              "  2,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  7,\n",
              "  3,\n",
              "  9,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  4,\n",
              "  8,\n",
              "  1,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  4,\n",
              "  5,\n",
              "  7,\n",
              "  1,\n",
              "  3,\n",
              "  9,\n",
              "  8,\n",
              "  0,\n",
              "  1,\n",
              "  7,\n",
              "  5,\n",
              "  8,\n",
              "  2,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  1,\n",
              "  8,\n",
              "  9,\n",
              "  8,\n",
              "  2,\n",
              "  9,\n",
              "  9,\n",
              "  2,\n",
              "  7,\n",
              "  5,\n",
              "  7,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  2,\n",
              "  7,\n",
              "  1,\n",
              "  6,\n",
              "  4,\n",
              "  0,\n",
              "  4,\n",
              "  6,\n",
              "  9,\n",
              "  7,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  7,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  9,\n",
              "  5,\n",
              "  4,\n",
              "  2,\n",
              "  7,\n",
              "  8,\n",
              "  1,\n",
              "  3,\n",
              "  4,\n",
              "  3,\n",
              "  7,\n",
              "  6,\n",
              "  9,\n",
              "  8,\n",
              "  0,\n",
              "  6,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  8,\n",
              "  4,\n",
              "  0,\n",
              "  1,\n",
              "  8,\n",
              "  8,\n",
              "  1,\n",
              "  5,\n",
              "  7,\n",
              "  6,\n",
              "  4,\n",
              "  5,\n",
              "  8,\n",
              "  7,\n",
              "  1,\n",
              "  9,\n",
              "  1,\n",
              "  9,\n",
              "  8,\n",
              "  4,\n",
              "  7,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  2,\n",
              "  6,\n",
              "  6,\n",
              "  7,\n",
              "  1,\n",
              "  6,\n",
              "  8,\n",
              "  1,\n",
              "  9,\n",
              "  7,\n",
              "  8,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  8,\n",
              "  8,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  5,\n",
              "  0,\n",
              "  8,\n",
              "  8,\n",
              "  7,\n",
              "  9,\n",
              "  9,\n",
              "  0,\n",
              "  9,\n",
              "  4,\n",
              "  1,\n",
              "  3,\n",
              "  6,\n",
              "  6,\n",
              "  4,\n",
              "  4,\n",
              "  7,\n",
              "  5,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  3,\n",
              "  2,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  9,\n",
              "  9,\n",
              "  7,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  6,\n",
              "  7,\n",
              "  4,\n",
              "  9,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  6,\n",
              "  7,\n",
              "  5,\n",
              "  7,\n",
              "  6,\n",
              "  8,\n",
              "  9,\n",
              "  0,\n",
              "  9,\n",
              "  4,\n",
              "  4,\n",
              "  7,\n",
              "  0,\n",
              "  9,\n",
              "  4,\n",
              "  9,\n",
              "  6,\n",
              "  9,\n",
              "  4,\n",
              "  5,\n",
              "  7,\n",
              "  9,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  1,\n",
              "  4,\n",
              "  3,\n",
              "  9,\n",
              "  6,\n",
              "  5,\n",
              "  6,\n",
              "  9,\n",
              "  3,\n",
              "  3,\n",
              "  5,\n",
              "  0,\n",
              "  7,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  6,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  5,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  9,\n",
              "  8,\n",
              "  4,\n",
              "  9,\n",
              "  8,\n",
              "  0,\n",
              "  2,\n",
              "  6,\n",
              "  4,\n",
              "  4,\n",
              "  0,\n",
              "  1,\n",
              "  8,\n",
              "  8,\n",
              "  3,\n",
              "  6,\n",
              "  9,\n",
              "  6,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  7,\n",
              "  6,\n",
              "  5,\n",
              "  3,\n",
              "  0,\n",
              "  5,\n",
              "  0,\n",
              "  5,\n",
              "  0,\n",
              "  8,\n",
              "  2,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  7,\n",
              "  6,\n",
              "  7,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  5,\n",
              "  5,\n",
              "  0,\n",
              "  1,\n",
              "  7,\n",
              "  6,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  7,\n",
              "  7,\n",
              "  1,\n",
              "  5,\n",
              "  9,\n",
              "  4,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  9,\n",
              "  9,\n",
              "  6,\n",
              "  7,\n",
              "  1,\n",
              "  8,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  0,\n",
              "  5,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  3,\n",
              "  7,\n",
              "  2,\n",
              "  9,\n",
              "  3,\n",
              "  8,\n",
              "  7,\n",
              "  8,\n",
              "  2,\n",
              "  7,\n",
              "  9,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  6,\n",
              "  2,\n",
              "  3,\n",
              "  2,\n",
              "  8,\n",
              "  0,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  1,\n",
              "  7,\n",
              "  7,\n",
              "  8,\n",
              "  2,\n",
              "  9,\n",
              "  2,\n",
              "  2,\n",
              "  4,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  6,\n",
              "  6,\n",
              "  6,\n",
              "  5,\n",
              "  1,\n",
              "  1,\n",
              "  7,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  3,\n",
              "  7,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  5,\n",
              "  5,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  4,\n",
              "  3,\n",
              "  7,\n",
              "  8,\n",
              "  8,\n",
              "  3,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  9,\n",
              "  4,\n",
              "  3,\n",
              "  8,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  5,\n",
              "  4,\n",
              "  9,\n",
              "  3,\n",
              "  1,\n",
              "  8,\n",
              "  9,\n",
              "  3,\n",
              "  9,\n",
              "  9,\n",
              "  2,\n",
              "  9,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  9,\n",
              "  8,\n",
              "  8,\n",
              "  1,\n",
              "  5,\n",
              "  3,\n",
              "  6,\n",
              "  8,\n",
              "  7,\n",
              "  6,\n",
              "  9,\n",
              "  8,\n",
              "  0,\n",
              "  6,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  5,\n",
              "  8,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  7,\n",
              "  6,\n",
              "  9,\n",
              "  7,\n",
              "  1,\n",
              "  5,\n",
              "  5,\n",
              "  6,\n",
              "  6,\n",
              "  3,\n",
              "  6,\n",
              "  2,\n",
              "  4,\n",
              "  7,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  1,\n",
              "  6,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  8,\n",
              "  5,\n",
              "  4,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  3,\n",
              "  9,\n",
              "  4,\n",
              "  7,\n",
              "  9,\n",
              "  7,\n",
              "  3,\n",
              "  7,\n",
              "  2,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  6,\n",
              "  1,\n",
              "  2,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  8,\n",
              "  7,\n",
              "  3,\n",
              "  9,\n",
              "  8,\n",
              "  7,\n",
              "  7,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  4,\n",
              "  1,\n",
              "  5,\n",
              "  4,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  2,\n",
              "  8,\n",
              "  5,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  5,\n",
              "  7,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  3,\n",
              "  5,\n",
              "  ...],\n",
              " ['airplane',\n",
              "  'automobile',\n",
              "  'bird',\n",
              "  'cat',\n",
              "  'deer',\n",
              "  'dog',\n",
              "  'frog',\n",
              "  'horse',\n",
              "  'ship',\n",
              "  'truck'],\n",
              " {'airplane': 0,\n",
              "  'automobile': 1,\n",
              "  'bird': 2,\n",
              "  'cat': 3,\n",
              "  'deer': 4,\n",
              "  'dog': 5,\n",
              "  'frog': 6,\n",
              "  'horse': 7,\n",
              "  'ship': 8,\n",
              "  'truck': 9})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = DataLoader(train_data, batch_size = 100, shuffle = True)"
      ],
      "metadata": {
        "id": "gNnDAo72vgk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "collapsed": true,
        "id": "-hc0I1Ynw7hu",
        "outputId": "22e4e6fc-9933-4e8a-d0ad-0d9c88697e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</a>Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
              "\n",
              "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
              "iterable-style datasets with single- or multi-process loading, customizing\n",
              "loading order and optional automatic batching (collation) and memory pinning.\n",
              "\n",
              "See :py:mod:`torch.utils.data` documentation page for more details.\n",
              "\n",
              "Args:\n",
              "    dataset (Dataset): dataset from which to load the data.\n",
              "    batch_size (int, optional): how many samples per batch to load\n",
              "        (default: ``1``).\n",
              "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
              "        at every epoch (default: ``False``).\n",
              "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
              "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
              "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
              "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
              "        returns a batch of indices at a time. Mutually exclusive with\n",
              "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
              "        and :attr:`drop_last`.\n",
              "    num_workers (int, optional): how many subprocesses to use for data\n",
              "        loading. ``0`` means that the data will be loaded in the main process.\n",
              "        (default: ``0``)\n",
              "    collate_fn (Callable, optional): merges a list of samples to form a\n",
              "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
              "        map-style dataset.\n",
              "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
              "        into device/CUDA pinned memory before returning them.  If your data elements\n",
              "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
              "        see the example below.\n",
              "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
              "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
              "        the size of dataset is not divisible by the batch size, then the last batch\n",
              "        will be smaller. (default: ``False``)\n",
              "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
              "        from workers. Should always be non-negative. (default: ``0``)\n",
              "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
              "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
              "        input, after seeding and before data loading. (default: ``None``)\n",
              "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
              "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
              "        be used. (default: ``None``)\n",
              "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
              "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
              "        ``base_seed`` for workers. (default: ``None``)\n",
              "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
              "        in advance by each worker. ``2`` means there will be a total of\n",
              "        2 * num_workers batches prefetched across all workers. (default value depends\n",
              "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
              "        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n",
              "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
              "        the worker processes after a dataset has been consumed once. This allows to\n",
              "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
              "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
              "        ``True``.\n",
              "\n",
              "\n",
              ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
              "             cannot be an unpicklable object, e.g., a lambda function. See\n",
              "             :ref:`multiprocessing-best-practices` on more details related\n",
              "             to multiprocessing in PyTorch.\n",
              "\n",
              ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
              "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
              "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
              "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
              "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
              "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
              "             loading to avoid duplicate data.\n",
              "\n",
              "             However, if sharding results in multiple workers having incomplete last batches,\n",
              "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
              "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
              "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
              "             cases in general.\n",
              "\n",
              "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
              "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
              "             `Multi-process data loading`_.\n",
              "\n",
              ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
              "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
              "\n",
              ".. _multiprocessing context:\n",
              "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 125);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for features,labels in train_iter:\n",
        "  print(features)\n",
        "  break # on first 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J8eufzjpw-IG",
        "outputId": "1a54c3bf-f9f3-4533-e824-4ba8b4bea9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          ...,\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          ...,\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          ...,\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          ...,\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          ...,\n",
            "          [-1.0000, -0.9922, -1.0000,  ..., -1.0000, -0.9843, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          ...,\n",
            "          [-1.0000, -0.9922, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
            "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## nn.Linear(in,out)\n",
        "# nn.Conv2d(in_channels,out_channels,kernel_size)"
      ],
      "metadata": {
        "id": "aCKyXyv_xwRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(train_iter)\n",
        "feat, lab = next(iterator)\n",
        "x = feat[0]\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwct5j4-x1kr",
        "outputId": "54266ff9-c439-40f1-9547-a6ba6b1807f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ H_0 = \\frac{H+2P-K}{S} + 1 $, $W_0 = \\frac{W+2P-K}{S} + 1 $"
      ],
      "metadata": {
        "id": "j0UC0ibKzneb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv = nn.Conv2d(1, 6, 5)"
      ],
      "metadata": {
        "id": "If5ARgKDyk0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9j8dyhT1j1i",
        "outputId": "5d5efa13-0299-4749-a839-9849f38ead8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 kernels of size $1 * 5*5$"
      ],
      "metadata": {
        "id": "q5IxWFQ51vlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = conv(x)"
      ],
      "metadata": {
        "id": "yhzib1nf0aYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgkOTKJf0ise",
        "outputId": "545cb7a5-da83-4cad-e15e-d48f075d1504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 24, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(N,C,H,W)"
      ],
      "metadata": {
        "id": "JDlsUaRH0kft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pool1 = nn.MaxPool2d(2, 2)\n",
        "x2 = pool1(x1)\n",
        "x2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cki4Qg9Y09uI",
        "outputId": "c483bf44-6791-4391-9f0f-bc527079436e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 12, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,6,5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6, 6,5)\n",
        "    self.fc1 = nn.Linear(6*4*4 , 80)    #6*4*4 how?\n",
        "    self.fc2 = nn.Linear(80, 20)\n",
        "    self.fc3 = nn.Linear(20, 10) # classification problem for 10 classes\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = x.view(-1,6*4*4)  #why view how (-1,6*4*4)?\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "Model = CNN()"
      ],
      "metadata": {
        "id": "r7GhMZbg1WeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = feat[0]\n",
        "Model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuErWwP55Jpf",
        "outputId": "51842d46-6962-40fa-9e93-526523dfaf26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2060,  0.2773, -0.0885,  0.1114, -0.1032, -0.0211,  0.2460,  0.0767,\n",
              "         -0.0650, -0.0098]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training\n",
        "- Define Criterion\n",
        "- Optimizer\n",
        "---\n",
        "1. zero_grad()\n",
        "2. Forward Pass\n",
        "3. Loss compute\n",
        "4. Backprop\n",
        "5. Updation"
      ],
      "metadata": {
        "id": "xF9uApSj5MFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1 epoch = pass through entire dataset\n",
        "- 1 iteration = pass through 1 batch\n",
        "  - total points = 60000\n",
        "  - batch size = 100\n",
        "  - batches = 600"
      ],
      "metadata": {
        "id": "SbIFNeJx6kR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(Model.parameters(), lr = 0.001, momentum = 0.9)\n",
        "for epoch in range(3):\n",
        "  total_correct_pts = 0\n",
        "  for features, labels in train_iter:\n",
        "    optimizer.zero_grad\n",
        "    output = Model(features)\n",
        "    ls = Loss(output, labels)\n",
        "    ls.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    corr = torch.argmax(output, axis = 1) == torch.as_tensor(labels)\n",
        "    total_correct = torch.count_nonzero(corr)\n",
        "    total_correct_pts += total_correct\n",
        "  print(total_correct_pts/60000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yR_5fSU57Lt",
        "outputId": "c6f85a79-dc85-4651-f593-e4fec57defaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1011)\n",
            "tensor(0.1000)\n",
            "tensor(0.0994)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.FashionMNIST('.data', train = False, download = True)"
      ],
      "metadata": {
        "id": "VB57rJP_7_fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_iter = DataLoader(test_data, shuffle = False, batch_size = 100)"
      ],
      "metadata": {
        "id": "C3_NBv9F8xOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model.eval()\n",
        "test_output = Model()"
      ],
      "metadata": {
        "id": "biakQdBT9Cxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_corr = 0\n",
        "for data in test_iter:\n",
        "  feat, lab = data\n",
        "  test_out = Model(feat)\n",
        "\n",
        "  corr_classes = torch.argmax(test_out, axis = 1) == torch.as_tensor(lab)\n",
        "  tcd = torch.count_nonzero(corr_classes)\n",
        "  test_corr+= tcd\n",
        "\n",
        "print(test_corr/10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FXdwxasf9VW3",
        "outputId": "111ef696-4e35-4ba4-df1f-e41a82e757a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-e62434cee023>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtest_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
          ]
        }
      ]
    }
  ]
}
